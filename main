# Steven Hu Kaggle-Titanic#importsimport pandas as pdfrom pandas import Series, DataFrameimport numpy as npimport matplotlib.pyplot as pltfrom sklearn.preprocessing import MinMaxScaler, MaxAbsScalerfrom sklearn.preprocessing import PolynomialFeaturesfrom plot_custom import plot_learning_curve#Machine learning algorithmfrom sklearn.linear_model import LogisticRegressionCVfrom sklearn.model_selection import ShuffleSplitimport sklearn.preprocessingfrom sklearn.model_selection import learning_curvefrom sklearn import neural_network as NeuralNetworkfrom sklearn.neural_network import multilayer_perceptron as MLPfrom sklearn.svm import SVCtitanic_df = pd.read_csv("./train.csv")test_df = pd.read_csv("./test.csv")titanic_df.head()print("---------------------")titanic_df.info()print("-------------")test_df.info()#Data Precessing## drop useless columnstitanic_df.drop(['PassengerId','Name','Ticket'], axis=1, inplace=True)test_df.drop(['Name', 'Ticket'], axis=1, inplace=True)### the 'Cabin' column has too many NaN, so droptitanic_df.drop(['Cabin'], axis=1, inplace=True)test_df.drop(['Cabin'], axis=1, inplace=True)##'Embarked'titanic_df['Embarked'].fillna('S', inplace=True)titanic_df['Embarked'].replace('C', 1, inplace=True)titanic_df['Embarked'].replace('Q', 2, inplace=True)titanic_df['Embarked'].replace('S', 3, inplace=True)test_df['Embarked'].fillna('S', inplace=True)test_df['Embarked'].replace('C', 1, inplace=True)test_df['Embarked'].replace('Q', 2, inplace=True)test_df['Embarked'].replace('S', 3, inplace=True)##'Fare'test_df['Fare'].fillna(test_df['Fare'].mean(), inplace=True)titanic_df['Fare'] = titanic_df['Fare'].astype(int)test_df['Fare'] = titanic_df['Fare'].astype(int)## 'Age'titanic_age_random = np.random.randint(titanic_df['Age'].mean()-titanic_df['Age'].std(), titanic_df['Age'].mean() + titanic_df['Age'].std(), titanic_df['Age'].isnull().sum())titanic_df['Age'][np.isnan(titanic_df['Age'])] = titanic_age_randomtest_age_random = np.random.randint(test_df['Age'].mean()-test_df['Age'].std(),test_df['Age'].mean() + test_df['Age'].std(), test_df['Age'].isnull().sum())test_df['Age'][np.isnan(test_df['Age'])] = test_age_randomtitanic_df['Age'] = titanic_df['Age'].astype(int)test_df['Age'] = test_df['Age'].astype(int)## 'Sex'titanic_df['Sex'].replace('male', 0, inplace=True)titanic_df['Sex'].replace('female', 1, inplace=True)test_df['Sex'].replace('male', 0, inplace=True)test_df['Sex'].replace('female', 1, inplace=True)## Data sets partitionrow, column = titanic_df.shapeX_train = titanic_df.drop('Survived', axis=1)Y_train = titanic_df['Survived']# ###Train sets## train_sets_size = int(0.8*row)# X_train = X_preprocessing.iloc[:train_sets_size, :].values# Y_train = Y_preprocessing,iloc[:train_sets_size, :].values## ###Cross-Validation sets# # cv_sets_size = int(0.2*row)# X_cv = X_preprocessing.iloc[train_sets_size:, :].values# Y_cv = Y_preprocessing.iloc[train_sets_size:, :].values###Test setsX_test  = test_df.drop("PassengerId", axis=1).copy()#Machine Learning#Preprocessing dataX_train = PolynomialFeatures(2).fit_transform(X_train)# X_train_scaler = MaxAbsScaler().fit_transform(X_train_ploy)X_test = PolynomialFeatures(2).fit_transform(X_test)# X_test = MaxAbsScaler().fit_transform(X_test)##LR with cv wrappedclf = LogisticRegressionCV(cv=10, n_jobs=-1, max_iter=300)clf.fit(X_train, Y_train)Y_test = clf.predict(X_test)# print(clf.score(X_preprocessing, Y_preprocessing))#learing curvescv = ShuffleSplit(n_splits=3, test_size=0.2)train_sizes = [100, 200, 300, 400, 500, 600, 700]plot_learning_curve(estimator=clf, title="learining curves", X=X_train, Y=Y_train, train_sizes=train_sizes, cv=cv )plt.show()#Submissionsubmission = pd.DataFrame({'PassengerId': test_df['PassengerId'],                       'Survived': Y_test})Y_pred_m = submission.as_matrix()submission.to_csv('submission.csv', index=False)